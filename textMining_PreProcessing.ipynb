{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e4cc545",
      "metadata": {
        "id": "9e4cc545"
      },
      "source": [
        "# Text Mining in Social Networks ‚Äî Preprocessing Demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions:\n",
        "\n",
        "1Ô∏è‚É£ You can enter one or more tweets manually.\n",
        "   - Type each tweet and press \"Enter\" after each.\n",
        "   - When you‚Äôre done, just press \"Enter\" again on a blank line.\n",
        "\n",
        "2Ô∏è‚É£ If you don‚Äôt want to enter anything, just press \"Enter\", the program will run on the default dataset.\n",
        "\n",
        "\n",
        "________________________________________________________\n",
        "Example:\n",
        "I love my new iPhone!! It's absolutely amazing üòç\n",
        "\n",
        "  Life is great‚Ä¶ said no one during exams üòí\n"
      ],
      "metadata": {
        "id": "XkgIxJXuD87i"
      },
      "id": "XkgIxJXuD87i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d011e70a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d011e70a",
        "outputId": "da47b687-5238-40c4-da8b-ad942d7b66d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15670698",
      "metadata": {
        "id": "15670698"
      },
      "source": [
        "## Enter your tweets (leave blank and run to use default dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a7e34a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7a7e34a",
        "outputId": "6947f155-e59c-43a0-cc9e-628ea2fc3055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      TEXT MINING IN SOCIAL NETWORKS ‚Äî PREPROCESSING DEMO\n",
            "=================================================================\n",
            "Enter tweet (or press Enter to finish): \n",
            "\n",
            "No input provided ‚Äî running on default dataset...\n",
            "\n",
            "\n",
            "Original Data:\n",
            "\n",
            "             user                                               text\n",
            "0       @elonmusk  Good thing I never tweet anything controversia...\n",
            "1  @taylorswift13  Every single one of you made this album possib...\n",
            "2      @BillGates  People think innovation is just about ideas. I...\n",
            "3          @Oprah  When I said ‚ÄòYou get a car!‚Äô, I didn‚Äôt mean yo...\n",
            "4      @JeffBezos  I love reading tweets about how easy it must b...\n",
            "5           @NASA  After traveling nearly 300 million miles, Pers...\n",
            "6    @BarackObama  I keep reminding young people: post with purpo...\n",
            "7       @elonmusk  Just for fun, I changed the Twitter logo to a ...\n",
            "8      @neiltyson  Every time I see someone arguing that Earth is...\n",
            "9       @ladygaga  Performing live again after two years feels un...\n",
            "\n",
            "================== CLEANED DATA (Before & After) ==================\n",
            "\n",
            "Tweet 1: Good thing I never tweet anything controversial‚Ä¶ except for the time I said Tesla stock was too high, or Dogecoin was the future, or when I named my kid after an encryption algorithm ü§∑‚Äç‚ôÇÔ∏è.\n",
            "Cleaned : good thing never tweet anything controversial except time said tesla stock high dogecoin future named kid encryption algorithm\n",
            "----------------------------------------------------------------------\n",
            "Tweet 2: Every single one of you made this album possible. From late-night writing sessions to surprise releases ‚Äî your love made the magic real. Forever grateful ‚ù§Ô∏è #Swifties #ThankYou\n",
            "Cleaned : every single one made album possible latenight writing session surprise release love made magic real forever grateful\n",
            "----------------------------------------------------------------------\n",
            "Tweet 3: People think innovation is just about ideas. It‚Äôs also about staying calm when your prototype catches fire, your investor ghosts you, and your code breaks five minutes before the demo. Fun times.\n",
            "Cleaned : people think innovation idea also staying calm prototype catch fire investor ghost code break five minute demo fun time\n",
            "----------------------------------------------------------------------\n",
            "Tweet 4: When I said ‚ÄòYou get a car!‚Äô, I didn‚Äôt mean you get a global pandemic. Life‚Äôs surprises have a strange sense of humor. But keep your spirits high ‚Äî gratitude is the best immunity.\n",
            "Cleaned : said get car didnt mean get global pandemic life surprise strange sense humor keep spirit high gratitude best immunity\n",
            "----------------------------------------------------------------------\n",
            "Tweet 5: I love reading tweets about how easy it must be to run a space company. Sure, because rockets, physics, and orbital trajectories are just weekend hobbies, right? üòè #SarcasmModeOn\n",
            "Cleaned : love reading tweet easy must run space company sure rocket physic orbital trajectory weekend hobby right\n",
            "----------------------------------------------------------------------\n",
            "Tweet 6: After traveling nearly 300 million miles, Perseverance has safely landed on Mars! Data looks great, instruments are stable, and we just received the first panoramic image. #Mars2020 #MissionAccomplished\n",
            "Cleaned : traveling nearly 300 million mile perseverance safely landed mar data look great instrument stable received first panoramic image\n",
            "----------------------------------------------------------------------\n",
            "Tweet 7: I keep reminding young people: post with purpose. The internet never forgets, even when you wish it would. Choose your words wisely ‚Äî they echo longer than you think.\n",
            "Cleaned : keep reminding young people post purpose internet never forgets even wish would choose word wisely echo longer think\n",
            "----------------------------------------------------------------------\n",
            "Tweet 8: Just for fun, I changed the Twitter logo to a Shiba Inu for a day. Didn‚Äôt expect crypto markets to explode. Maybe memes are the most powerful economic forces of our time üòÇ #DogeDay\n",
            "Cleaned : fun changed twitter logo shiba inu day didnt expect crypto market explode maybe meme powerful economic force time\n",
            "----------------------------------------------------------------------\n",
            "Tweet 9: Every time I see someone arguing that Earth is flat, I remember ‚Äî ships disappear bottom-first over the horizon, not because they‚Äôre shy, but because physics still works.\n",
            "Cleaned : every time see someone arguing earth flat remember ship disappear bottomfirst horizon theyre shy physic still work\n",
            "----------------------------------------------------------------------\n",
            "Tweet 10: Performing live again after two years feels unreal ‚Äî the lights, the energy, the fans singing every word. My heart is full and my voice is hoarse. Wouldn‚Äôt trade this for anything üí´ #Grateful\n",
            "Cleaned : performing live two year feel unreal light energy fan singing every word heart full voice hoarse wouldnt trade anything\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"      TEXT MINING IN SOCIAL NETWORKS ‚Äî PREPROCESSING DEMO\")\n",
        "print(\"=\"*65)\n",
        "\n",
        "\n",
        "\n",
        "# STEP 0: Input or Default Dataset\n",
        "\n",
        "user_inputs = []\n",
        "\n",
        "while True:\n",
        "    tweet = input(\"Enter tweet (or press Enter to finish): \").strip()\n",
        "    if tweet == \"\":\n",
        "        break\n",
        "    user_inputs.append(tweet)\n",
        "\n",
        "if user_inputs:\n",
        "    data = pd.DataFrame({\n",
        "        'id': range(1, len(user_inputs)+1),\n",
        "        'user': ['@user'] * len(user_inputs),\n",
        "        'text': user_inputs\n",
        "    })\n",
        "else:\n",
        "    print(\"\\nNo input provided ‚Äî running on default dataset...\\n\")\n",
        "    data = pd.DataFrame({\n",
        "        'id': range(1, 11),\n",
        "        'user': [\n",
        "            '@elonmusk','@taylorswift13','@BillGates','@Oprah','@JeffBezos',\n",
        "            '@NASA','@BarackObama','@elonmusk','@neiltyson','@ladygaga'\n",
        "        ],\n",
        "        'text': [\n",
        "            \"Good thing I never tweet anything controversial‚Ä¶ except for the time I said Tesla stock was too high, or Dogecoin was the future, or when I named my kid after an encryption algorithm ü§∑‚Äç‚ôÇÔ∏è.\",\n",
        "            \"Every single one of you made this album possible. From late-night writing sessions to surprise releases ‚Äî your love made the magic real. Forever grateful ‚ù§Ô∏è #Swifties #ThankYou\",\n",
        "            \"People think innovation is just about ideas. It‚Äôs also about staying calm when your prototype catches fire, your investor ghosts you, and your code breaks five minutes before the demo. Fun times.\",\n",
        "            \"When I said ‚ÄòYou get a car!‚Äô, I didn‚Äôt mean you get a global pandemic. Life‚Äôs surprises have a strange sense of humor. But keep your spirits high ‚Äî gratitude is the best immunity.\",\n",
        "            \"I love reading tweets about how easy it must be to run a space company. Sure, because rockets, physics, and orbital trajectories are just weekend hobbies, right? üòè #SarcasmModeOn\",\n",
        "            \"After traveling nearly 300 million miles, Perseverance has safely landed on Mars! Data looks great, instruments are stable, and we just received the first panoramic image. #Mars2020 #MissionAccomplished\",\n",
        "            \"I keep reminding young people: post with purpose. The internet never forgets, even when you wish it would. Choose your words wisely ‚Äî they echo longer than you think.\",\n",
        "            \"Just for fun, I changed the Twitter logo to a Shiba Inu for a day. Didn‚Äôt expect crypto markets to explode. Maybe memes are the most powerful economic forces of our time üòÇ #DogeDay\",\n",
        "            \"Every time I see someone arguing that Earth is flat, I remember ‚Äî ships disappear bottom-first over the horizon, not because they‚Äôre shy, but because physics still works.\",\n",
        "            \"Performing live again after two years feels unreal ‚Äî the lights, the energy, the fans singing every word. My heart is full and my voice is hoarse. Wouldn‚Äôt trade this for anything üí´ #Grateful\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "print(\"\\nOriginal Data:\\n\")\n",
        "print(data[['user', 'text']])\n",
        "\n",
        "\n",
        "# STEP 1: Cleaning Function\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)                # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)                   # Remove mentions\n",
        "    text = re.sub(r'#\\w+', '', text)                   # Remove hashtags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)                # Remove punctuation\n",
        "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)# Remove emojis\n",
        "    text = text.lower()                                # Lowercase\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()           # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['clean_text'] = data['text'].apply(clean_text)\n",
        "\n",
        "\n",
        "# STEP 2: Tokenization\n",
        "\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "data['tokens'] = data['clean_text'].apply(tokenizer.tokenize)\n",
        "\n",
        "\n",
        "# STEP 3: Stopword Removal\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['tokens'] = data['tokens'].apply(lambda tokens: [t for t in tokens if t not in stop_words])\n",
        "\n",
        "\n",
        "# STEP 4: Lemmatization\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "data['tokens'] = data['tokens'].apply(lambda tokens: [lemmatizer.lemmatize(t) for t in tokens])\n",
        "\n",
        "\n",
        "# STEP 5: Rejoin Clean Text\n",
        "\n",
        "data['final_text'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "\n",
        "# DISPLAY RESULTS\n",
        "\n",
        "print(\"\\n================== CLEANED DATA (Before & After) ==================\\n\")\n",
        "for i in range(len(data)):\n",
        "    print(f\"Tweet {i+1}: {data.text[i]}\")\n",
        "    print(f\"Cleaned : {data.final_text[i]}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}